{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the raw ICTRP COVID-19 registered trials CSV, cuts it down to only the fields we need, and cleans/processes the data using techniques developed for covid19.trialstracker.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent = str(Path(cwd).parents[0])\n",
    "sys.path.append(parent)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(parent + '/data/ictrp_data/COVID19-web_1July2021.csv', dtype={'Phase': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_cleaning import enrollment_dates, fix_date, fix_errors, d_c\n",
    "\n",
    "#This is fixes for known broken enrollement dates    \n",
    "enrollment_errors= {\n",
    "    'IRCT20200310046736N1': ['14/06/2641', '2020-04-01'],\n",
    "    'EUCTR2020-001909-22-FR': ['nan', '2020-04-29']\n",
    "}\n",
    "\n",
    "reg_date_errors = {\n",
    "    'RBR-5p8nzk6': ['0', '20201125'],\n",
    "    'RBR-8tygcz7': ['0', '20201201']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fix_errors(enrollment_errors, df, 'Date enrollement')\n",
    "\n",
    "df = fix_errors(reg_date_errors, df, 'Date registration3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date enrollement'] = df['Date enrollement'].apply(enrollment_dates)\n",
    "\n",
    "df['Date registration'] = pd.to_datetime(df['Date registration3'], format='%Y%m%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_cleaning import enroll_extract\n",
    "\n",
    "#Extracting target enrollment\n",
    "size = df['Target size'].tolist()\n",
    "\n",
    "df['target_enrollment'] = enroll_extract(size)\n",
    "\n",
    "#Creating retrospective registration\n",
    "df['retrospective_registration'] = np.where(df['Date registration'] > df['Date enrollement'], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only what we need right now\n",
    "\n",
    "cols = ['TrialID', 'Source Register', 'Date registration', 'Date enrollement', 'retrospective_registration', \n",
    "        'Primary sponsor', 'Recruitment Status', 'Phase', 'Study type', 'Countries', 'Public title', \n",
    "        'Intervention', 'target_enrollment', 'web address', 'results yes no', 'results url link']\n",
    "\n",
    "df_cond = df[cols].reset_index(drop=True)\n",
    "\n",
    "#renaming columns to match old format so I don't have to change them throughout\n",
    "df_cond.columns = ['TrialID', 'Source_Register', 'Date_registration', 'Date_enrollement', \n",
    "                   'retrospective_registration', 'Primary_sponsor', 'Recruitment_Status', 'Phase', 'Study_type', \n",
    "                   'Countries', 'Public_title', 'Intervention', 'target_enrollment', 'web_address', \n",
    "                   'has_results', 'results_url_link']\n",
    "\n",
    "print(f'The ICTRP shows {len(df_cond)} trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cond_all = df_cond.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning various fields. \n",
    "#One important thing we have to do is make sure there are no nulls or else the data won't properly load onto the website\n",
    "\n",
    "#semi-colons in the intervention field mess with CSV\n",
    "df_cond_all['Intervention'] = df_cond_all['Intervention'].str.replace(';', '')\n",
    "\n",
    "#Study Type\n",
    "obv_replace = ['Observational [Patient Registry]', 'observational', 'Observational Study']\n",
    "int_replace = ['interventional', 'Interventional clinical trial of medicinal product', 'Treatment', \n",
    "               'INTERVENTIONAL', 'Intervention', 'Interventional Study', 'PMS']\n",
    "hs_replace = ['Health services reaserch', 'Health Services reaserch', 'Health Services Research']\n",
    "\n",
    "df_cond_all['Study_type'] = (df_cond_all['Study_type'].str.replace(' study', '')\n",
    "                             .replace(obv_replace, 'Observational').replace(int_replace, 'Interventional')\n",
    "                             .replace('Epidemilogical research', 'Epidemiological research')\n",
    "                             .replace(hs_replace, 'Health services research')\n",
    "                             .replace('Others,meta-analysis etc', 'Other'))\n",
    "\n",
    "#phase\n",
    "df_cond_all['Phase'] = df_cond_all['Phase'].fillna('Not Applicable')\n",
    "na = ['0', 'Retrospective study', 'Not applicable', 'New Treatment Measure Clinical Study', 'Not selected', \n",
    "      'Phase 0', 'Diagnostic New Technique Clincal Study', '0 (exploratory trials)', 'Not Specified']\n",
    "p1 = ['1', 'Early Phase 1', 'I', 'Phase-1', 'Phase I']\n",
    "p12 = ['1-2', '2020-02-01 00:00:00', 'Phase I/II', 'Phase 1 / Phase 2', 'Phase 1/ Phase 2', '02-Jan',\n",
    "       'Human pharmacology (Phase I): yes\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): no\\n']\n",
    "p2 = ['2', 'II', 'Phase II', 'IIb', 'Phase-2', 'Phase2',\n",
    "      'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): no\\n']\n",
    "p23 = ['Phase II/III', '2020-03-02 00:00:00', 'II-III', 'Phase 2 / Phase 3', 'Phase 2/ Phase 3', '2-3', '03-Feb',\n",
    "       'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): no\\n']\n",
    "p3 = ['3', 'Phase III', 'Phase-3', 'III',\n",
    "      'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): no\\n']\n",
    "p34 = ['Phase 3/ Phase 4', 'Phase III/IV',\n",
    "       'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): yes\\n']\n",
    "p4 = ['4', 'IV', 'Post Marketing Surveillance', 'Phase IV', 'PMS',\n",
    "      'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): yes\\n']\n",
    "\n",
    "df_cond_all['Phase'] = (df_cond_all['Phase'].replace(na, 'Not Applicable').replace(p1, 'Phase 1')\n",
    "                        .replace(p12, 'Phase 1/Phase 2').replace(p2, 'Phase 2')\n",
    "                        .replace(p23, 'Phase 2/Phase 3').replace(p3, 'Phase 3').replace(p34, 'Phase 3/Phase 4')\n",
    "                        .replace(p4, 'Phase 4'))\n",
    "\n",
    "#Fixing Observational studies incorrectly given a Phase in ICTRP data\n",
    "m = ((df_cond_all.Phase.str.contains('Phase')) & (df_cond_all.Study_type == 'Observational'))\n",
    "df_cond_all['Phase'] = df_cond_all.Phase.where(~m, 'Not Applicable')\n",
    "\n",
    "#Recruitment Status\n",
    "df_cond_all['Recruitment_Status'] = df_cond_all['Recruitment_Status'].replace('Not recruiting', 'Not Recruiting')\n",
    "df_cond_all['Recruitment_Status'] = df_cond_all['Recruitment_Status'].fillna('No Status Given')\n",
    "\n",
    "#Get rid of messy accents\n",
    "from lib.data_cleaning import norm_names\n",
    "    \n",
    "df_cond_all['Primary_sponsor'] = df_cond_all.Primary_sponsor.apply(norm_names)\n",
    "df_cond_all['Primary_sponsor'] = df_cond_all['Primary_sponsor'].replace('NA', 'No Sponsor Name Given')\n",
    "df_cond_all['Primary_sponsor'] = df_cond_all['Primary_sponsor'].replace('nan', 'No Sponsor Name Given')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countries\n",
    "df_cond_all['Countries'] = df_cond_all['Countries'].fillna('No Country Given').replace('??', 'No Country Given')\n",
    "\n",
    "china_corr = ['Chian', 'China?', 'Chinese', 'Wuhan', 'Chinaese', 'china', 'Taiwan, Province Of China', \n",
    "              \"The People's Republic of China\"]\n",
    "\n",
    "country_values = df_cond_all['Countries'].tolist()\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for c in country_values:\n",
    "    country_list = []\n",
    "    if isinstance(c, float):\n",
    "        country_list.append('No Sponsor Name Given')\n",
    "    elif c == 'No Sponsor Name Given':\n",
    "        country_list.append('No Sponsor Name Given')\n",
    "    elif c in china_corr:\n",
    "        country_list.append('China')\n",
    "    elif c in ['Iran (Islamic Republic of)', 'Iran, Islamic Republic of']:\n",
    "        country_list.append('Iran')\n",
    "    elif c in ['Viet nam', 'Viet Nam']:\n",
    "        country_list.append('Vietnam')\n",
    "    elif c in ['Korea, Republic of', 'Korea, Republic Of', 'KOREA'] :\n",
    "        country_list.append('South Korea')\n",
    "    elif c in ['USA', 'United States of America', 'U.S.']:\n",
    "        country_list.append('United States')\n",
    "    elif c == 'Japan,Asia(except Japan),Australia,Europe':\n",
    "        country_list = ['Japan', 'Australia', 'Asia', 'Europe']\n",
    "    elif c == 'Japan,Asia(except Japan),North America,South America,Australia,Europe,Africa':\n",
    "        country_list = ['Japan, Asia(except Japan), North America, South America, Australia, Europe, Africa']\n",
    "    elif c == 'The Netherlands':\n",
    "        country_list.append('Netherlands')\n",
    "    elif c == 'England':\n",
    "        country_list.append('United Kingdom')\n",
    "    elif c == 'Japan,North America':\n",
    "        country_list = ['Japan', 'North America']\n",
    "    elif c == 'Czechia':\n",
    "        country_list.append('Czech Republic')\n",
    "    elif c == 'ASIA':\n",
    "        country_list.append('Asia')\n",
    "    elif c == 'EUROPE':\n",
    "        country_list.append('Europe')\n",
    "    elif c == 'MALAYSIA':\n",
    "        country_list.append('Malaysia')\n",
    "    elif c in ['Congo', 'Congo, Democratic Republic', 'Congo, The Democratic Republic of the']:\n",
    "        country_list.append('Democratic Republic of Congo')\n",
    "    elif c in [\"C√¥te D'Ivoire\", 'Cote Divoire', \"CÃ´te D'Ivoire\"]:\n",
    "        country_list.append(\"Cote d'Ivoire\")\n",
    "    elif c in ['Türkiye', 'TÃ¼rkiye', 'TÃƒÂ¼rkiye']:\n",
    "        country_list.append('Turkey')\n",
    "    elif c == 'SOUTH AMERICA':\n",
    "        country_list.append('South America')\n",
    "    elif c == 'AFRICA':\n",
    "        country_list.append('Africa')\n",
    "    elif c == 'italy':\n",
    "        country_list.append('Italy')\n",
    "    elif ';' in c:\n",
    "        c_list = c.split(';')\n",
    "        unique_values = list(set(c_list))\n",
    "        for v in unique_values:\n",
    "            if v in china_corr:\n",
    "                country_list.append('China')\n",
    "            elif v in ['Iran (Islamic Republic of)', 'Iran, Islamic Republic of']:\n",
    "                country_list.append('Iran')\n",
    "            elif v in ['Korea, Republic of', 'Korea, Republic Of', 'KOREA']:\n",
    "                country_list.append('South Korea')\n",
    "            elif v in ['Viet nam', 'Viet Nam']:\n",
    "                country_list.append('Vietnam')\n",
    "            elif v in ['USA', 'United States of America']:\n",
    "                country_list.append('United States')\n",
    "            elif v == 'The Netherlands':\n",
    "                country_list.append('Netherlands')\n",
    "            elif v == 'England':\n",
    "                country_list.append('United Kingdom')\n",
    "            elif v == 'Czechia':\n",
    "                country_list.append('Czech Republic')\n",
    "            elif v == 'ASIA':\n",
    "                country_list.append('Asia')\n",
    "            elif v == 'EUROPE':\n",
    "                country_list.append('Europe')\n",
    "            elif v == 'MALAYSIA':\n",
    "                country_list.append('Malaysia')\n",
    "            elif v in ['Congo', 'Congo, Democratic Republic', 'Congo, The Democratic Republic of the']:\n",
    "                country_list.append('Democratic Republic of Congo')\n",
    "            elif v in [\"C√¥te D'Ivoire\", 'Cote Divoire', \"CÃ´te D'Ivoire\"]:\n",
    "                country_list.append(\"Cote d'Ivoire\")\n",
    "            elif v in ['Türkiye', 'TÃ¼rkiye', 'TÃƒÂ¼rkiye']:\n",
    "                country_list.append('Turkey')\n",
    "            elif v == 'SOUTH AMERICA':\n",
    "                country_list.append('South America')\n",
    "            elif v == 'AFRICA':\n",
    "                country_list.append('Africa')\n",
    "            elif v == 'italy':\n",
    "                country_list.append('Italy')\n",
    "            else:\n",
    "                country_list.append(v)\n",
    "    else:\n",
    "        country_list.append(c.strip())\n",
    "    new_list.append(', '.join(country_list))\n",
    "\n",
    "df_cond_all['Countries'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final organising\n",
    "\n",
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_all.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_all.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'retrospective_registration', \n",
    "           'recruitment_status', 'phase', 'study_type', 'countries', 'public_title', \n",
    "            'target_enrollment', 'web_address']\n",
    "\n",
    "df_intermediate = df_cond_all[reorder].reset_index(drop=True).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(df_intermediate)} total unique registered studies on the ICTRP')\n",
    "\n",
    "non_int = df_intermediate[((df_intermediate.study_type == 'Interventional') | (df_intermediate.study_type == 'Prevention'))].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(non_int)} are Interventional or on Prevention. We exclude {len(df_intermediate) - len(non_int)} at this setp')\n",
    "\n",
    "in_2020 = non_int[(non_int.date_registration >= pd.Timestamp(2020,1,1))].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(in_2020)} started since 1 Jan 2020. We exclude {len(non_int) - len(in_2020)} at this step')\n",
    "\n",
    "withdrawn = in_2020[~(in_2020.public_title.str.contains('Cancelled') | in_2020.public_title.str.contains('Retracted due to'))].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(withdrawn)} are not listed as cancelled/withdrawn. We exclude {len(in_2020) - len(withdrawn)} at this step but will exclude additional trials after scraping the registries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_scrape = withdrawn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_scrape.to_csv(parent + '/data/scrape_df_jul21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intermediate.to_csv(parent + '/data/cleaned_ictrp_1jul2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
