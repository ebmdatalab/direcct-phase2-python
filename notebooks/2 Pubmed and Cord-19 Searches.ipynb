{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the searches of PubMed and the CORD-19 Database for text representing trial registrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent = str(Path(cwd).parents[0])\n",
    "sys.path.append(parent)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from xml.etree.ElementTree import tostring\n",
    "\n",
    "#Our searching function and lists of our regular expressions\n",
    "from lib.id_searches import search_text, ids_exact, prefixes, registry_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#If the archive exists, load it in.\n",
    "try:\n",
    "    from lib.id_searches import zip_load\n",
    "    archive_df = zip_load(parent + '/data/pubmed/pubmed_archive_14Jul_2021.csv.zip', \n",
    "                  'pubmed_archive_14Jul_2021.csv', index_col = 0)\n",
    "\n",
    "#If it doesn't exist, you can do a new PubMed search\n",
    "except FileNotFoundError:\n",
    "    from pymed import PubMed\n",
    "    from lib.credentials import email\n",
    "    from lib.id_searches import query, create_pubmed_archive\n",
    "    print('Archive file not found, conducting new PubMed search.')\n",
    "    pubmed = PubMed(tool=\"Pymed\", email=email)\n",
    "    results = pubmed.query(query, max_results=160000)\n",
    "    results_length = pubmed.getTotalResultsCount(query)\n",
    "    print(f'There are {results_length} results')\n",
    "          \n",
    "    print('Archiving results. This may take a few minutes.')\n",
    "    ##results_list = list(results) #This can take a while\n",
    "    ##print(f'Transformed {len(results_list)} results')\n",
    "    \n",
    "    #archive_df = create_pubmed_archive(results_list)\n",
    "    archive = []\n",
    "    for r in tqdm(results, total=results_length):\n",
    "        rec = create_pubmed_archive(r)\n",
    "        if rec:\n",
    "            archive.append(rec)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    archive_df = pd.DataFrame(archive)\n",
    "    archive_df.to_csv(parent + '/data/pubmed/pubmed_archive_14Jul_2021.csv')\n",
    "    print('Archive created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_data = archive_df.xml_json.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of these when we don't need them anymore to save some memory\n",
    "del archive\n",
    "del archive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pubmed_dicts = []\n",
    "for rec in tqdm(pubmed_data):\n",
    "    pm_dict = json.loads(rec)['PubmedArticle']\n",
    "    entry_dict = {}\n",
    "    art_ids = pm_dict['PubmedData']['ArticleIdList']['ArticleId']\n",
    "    entry_dict['source'] = 'PubMed'\n",
    "    entry_dict['pmid'] = pm_dict['MedlineCitation']['PMID']['#text']\n",
    "    entry_dict['doi'] = None\n",
    "    \n",
    "    if isinstance(pm_dict['MedlineCitation']['Article']['ArticleTitle'], str):\n",
    "        entry_dict['title'] = pm_dict['MedlineCitation']['Article']['ArticleTitle']\n",
    "    elif isinstance(pm_dict['MedlineCitation']['Article']['ArticleTitle'], dict):\n",
    "        try:\n",
    "            entry_dict['title'] = pm_dict['MedlineCitation']['Article']['ArticleTitle']['#text']\n",
    "        except KeyError:\n",
    "            entry_dict['title'] = pm_dict['MedlineCitation']['Article']['ArticleTitle']['b']\n",
    "    elif pm_dict['MedlineCitation']['Article']['ArticleTitle'] is None:\n",
    "        entry_dict['title'] = 'No Title'\n",
    "    \n",
    "    if isinstance(art_ids, list):\n",
    "        for x in art_ids:\n",
    "            if x['@IdType'] == 'doi':\n",
    "                entry_dict['doi'] = x['#text']\n",
    "    elif isinstance(art_ids, dict):\n",
    "        if art_ids['@IdType'] == 'doi':\n",
    "            entry_dict['doi'] = art_ids['#text']\n",
    "    try:\n",
    "        dbs =  pm_dict['MedlineCitation']['Article']['DataBankList']['DataBank']\n",
    "        accession_nums = []\n",
    "        if isinstance(dbs, list):\n",
    "            for x in dbs:\n",
    "                ans = x['AccessionNumberList']['AccessionNumber']\n",
    "                if isinstance(ans, list):\n",
    "                    accession_nums += ans\n",
    "                else:\n",
    "                    accession_nums.append(x)\n",
    "        elif isinstance(dbs, dict):\n",
    "            x = dbs['AccessionNumberList']['AccessionNumber']\n",
    "            if isinstance(x, list):\n",
    "                accession_nums += x\n",
    "            else:\n",
    "                accession_nums.append(x)\n",
    "                \n",
    "        if accession_nums:\n",
    "            entry_dict['accession'] = accession_nums\n",
    "        else:\n",
    "            entry_dict['accession'] = None\n",
    "    except KeyError:\n",
    "        entry_dict['accession'] = None\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        pub_type_list = []\n",
    "        pub_types = pm_dict['MedlineCitation']['Article']['PublicationTypeList']['PublicationType']\n",
    "        if isinstance(pub_types, list):\n",
    "            for pt in pub_types:\n",
    "                pub_type_list.append(pt['#text'])\n",
    "        elif isinstance(pub_types, dict):\n",
    "            pub_type_list.append(pub_types['#text'])\n",
    "        entry_dict['pub_types'] = pub_type_list\n",
    "    except KeyError:\n",
    "        entry_dict['pub_types'] = None\n",
    "    \n",
    "    try:\n",
    "        entry_dict['pub_types_raw'] = pm_dict['MedlineCitation']['Article']['PublicationTypeList']\n",
    "    except KeyError:\n",
    "        entry_dict['pub_types_raw'] = None\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        entry_dict['abstract'] = str(pm_dict['MedlineCitation']['Article']['Abstract']['AbstractText'])\n",
    "    except KeyError:\n",
    "        entry_dict['abstract'] = None\n",
    "\n",
    "    pubmed_dicts.append(entry_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for d in tqdm(pubmed_dicts):\n",
    "    d['abst_id_hits'] = search_text(ids_exact, d['abstract'])\n",
    "    d['reg_prefix_hits'] = search_text(prefixes, d['abstract'])\n",
    "    d['reg_name_hits'] = search_text(registry_names, d['abstract'])\n",
    "    if 'review' in d['title'].lower():\n",
    "        d['review_in_title'] = True\n",
    "    else:\n",
    "        d['review_in_title'] = False\n",
    "    try:\n",
    "        if 'Review' in d['pub_types']:\n",
    "            d['review_type'] = True\n",
    "        else:\n",
    "            d['review_type'] = False\n",
    "    except TypeError:\n",
    "        d['review_type'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pubmed_search_results = pd.DataFrame(pubmed_dicts)\n",
    "pubmed_search_results.to_csv(parent + '/data/pubmed/pubmed_search_results_jul2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(pubmed_search_results, open('pubmed_df_jul21.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching CORD-19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cord_df = pickle.load( open( \"cord_df.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cord_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = 'https://www.dropbox.com/s/b6oog6w4al4uxic/metadata.csv.zip?dl=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(md, compression='zip', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata = zip_load(parent + '/data/cord_19/metadata.csv.zip', 'metadata.csv', low_memory = False)\n",
    "metadata['publish_time'] = pd.to_datetime(metadata['publish_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a list of all the filenames for the papers that were published in 2020\n",
    "covid_19_arts = metadata[metadata.publish_time >= pd.Timestamp(2020,1,1)].sha.to_list()\n",
    "covid_19_pmc = metadata[metadata.publish_time >= pd.Timestamp(2020,1,1)].pmcid.to_list()\n",
    "recent_articles = []\n",
    "for c in covid_19_arts:\n",
    "    recent_articles.append(str(c) + '.json')\n",
    "\n",
    "recent_pmcs = []\n",
    "for p in covid_19_pmc:\n",
    "    recent_pmcs.append(str(p) + '.xml.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_hit_list = []\n",
    "with tarfile.open(parent+'/data/cord_19/document_parses.tar.gz', 'r:gz') as tar:\n",
    "    file_names = tar.getnames()\n",
    "    files = tar.getmembers()\n",
    "    for fn, f in zip(file_names, tqdm(files)):\n",
    "        name = fn.split('/')[-1]\n",
    "        doc_dict = {}\n",
    "        if name in recent_articles:\n",
    "            file = tar.extractfile(f)\n",
    "            content = file.read()\n",
    "            stringify = content.decode('utf-8')\n",
    "            j = json.loads(content)\n",
    "            doc_dict['file_name'] = j['paper_id']\n",
    "            doc_dict['source'] = 'cord_pdf'\n",
    "            doc_dict['id_hits'] = search_text(ids_exact, stringify)\n",
    "            doc_dict['reg_prefix_hits'] = search_text(prefixes, stringify)\n",
    "            doc_dict['reg_name_hits'] = search_text(registry_names, stringify)\n",
    "            doc_dict['title'] = j['metadata']['title']\n",
    "            if 'review' in doc_dict['title'].lower():\n",
    "                doc_dict['review_in_title'] = True\n",
    "            else:\n",
    "                doc_dict['review_in_title'] = False\n",
    "        elif name in recent_pmcs:\n",
    "            file = tar.extractfile(f)\n",
    "            content = file.read()\n",
    "            stringify = content.decode('utf-8')\n",
    "            j = json.loads(content)\n",
    "            doc_dict['file_name'] = j['paper_id']\n",
    "            doc_dict['source'] = 'cord_pmc'\n",
    "            doc_dict['id_hits'] = search_text(ids_exact, stringify)\n",
    "            doc_dict['reg_prefix_hits'] = search_text(prefixes, stringify)\n",
    "            doc_dict['reg_name_hits'] = search_text(registry_names, stringify)\n",
    "            doc_dict['title'] = j['metadata']['title']\n",
    "            if 'review' in doc_dict['title'].lower():\n",
    "                doc_dict['review_in_title'] = True\n",
    "            else:\n",
    "                doc_dict['review_in_title'] = False\n",
    "        else:\n",
    "            continue\n",
    "        if doc_dict:\n",
    "            cord_hit_list.append(doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_df = pd.DataFrame(cord_hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(cord_df, open('cord_df_jul21.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.id_searches import make_doi_url, trial_pub_type, dedupe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_pdf_merge = cord_df.merge(metadata[['sha', 'doi', 'pubmed_id', 'cord_uid', 'url']], how='left', left_on='file_name', right_on='sha').drop(['sha'], axis=1)\n",
    "\n",
    "cord_pmc_merge = cord_df.merge(metadata[['pmcid', 'doi', 'pubmed_id', 'cord_uid', 'url']], how='left', left_on='file_name', right_on='pmcid').drop(['pmcid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = cord_pdf_merge[cord_pdf_merge.doi.notnull()].append(cord_pmc_merge[cord_pmc_merge.doi.notnull()], ignore_index=True)\n",
    "\n",
    "final_cord = combined.loc[combined.astype(str).drop_duplicates().index].drop(['file_name'], axis=1).reset_index(drop=True)\n",
    "\n",
    "merged = final_cord.merge(pubmed_search_results, how='outer', left_on='pubmed_id', right_on='pmid').drop(['abstract', 'pub_types_raw'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_conds = [(merged.source_x.notnull() & merged.source_y.isna()), \n",
    "                (merged.source_x.isna() & merged.source_y.notnull()), \n",
    "                merged.source_x.notnull() & merged.source_y.notnull()]\n",
    "source_output = [merged.source_x, merged.source_y, 'mixed']\n",
    "\n",
    "merged['source'] = np.select(source_conds, source_output, None)\n",
    "merged.drop(['source_x', 'source_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_conds = [(merged.title_x.notnull() & merged.title_y.isna()), \n",
    "                (merged.title_x.isna() & merged.title_y.notnull()), \n",
    "                merged.title_x.notnull() & merged.title_y.notnull()]\n",
    "title_output = [merged.title_x, merged.title_y, merged.title_y]\n",
    "\n",
    "merged['title'] = np.select(title_conds, title_output, None)\n",
    "merged.drop(['title_x', 'title_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_conds = [(merged.doi_x.notnull() & merged.doi_y.isna()), \n",
    "                (merged.doi_x.isna() & merged.doi_y.notnull()), \n",
    "                merged.doi_x.notnull() & merged.doi_y.notnull()]\n",
    "doi_output = [merged.doi_x, merged.doi_y, merged.doi_y]\n",
    "\n",
    "merged['doi'] = np.select(doi_conds, doi_output, None)\n",
    "merged.drop(['doi_x', 'doi_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_conds = [(merged.pubmed_id.notnull() & merged.pmid.isna()), \n",
    "                (merged.pubmed_id.isna() & merged.pmid.notnull()), \n",
    "                merged.pubmed_id.notnull() & merged.pmid.notnull()]\n",
    "pmid_output = [merged.pubmed_id, merged.pmid, merged.pmid]\n",
    "\n",
    "merged['pm_id'] = np.select(pmid_conds, pmid_output, None)\n",
    "merged.drop(['pubmed_id', 'pmid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_title_conds = [(merged.review_in_title_x.notnull() & merged.review_in_title_y.isna()), \n",
    "                      (merged.review_in_title_x.isna() & merged.review_in_title_y.notnull()), \n",
    "                      (merged.review_in_title_x == True) | (merged.review_in_title_y == True), \n",
    "                      (merged.review_in_title_x == False) & (merged.review_in_title_y == False)]\n",
    "review_title_output = [merged.review_in_title_x, merged.review_in_title_y, True, False]\n",
    "\n",
    "merged['review_in_title'] = np.select(review_title_conds, review_title_output)\n",
    "merged.drop(['review_in_title_x', 'review_in_title_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_hits_cond = [merged.id_hits.notnull() & merged.abst_id_hits.isna(), \n",
    "                merged.id_hits.isna() & merged.abst_id_hits.notnull(), \n",
    "                merged.id_hits.notnull() & merged.abst_id_hits.notnull()]\n",
    "id_hits_output= [merged.id_hits, merged.abst_id_hits, merged.id_hits + merged.abst_id_hits]\n",
    "    \n",
    "    \n",
    "merged['trial_id_hits'] = np.select(id_hits_cond, id_hits_output, None)\n",
    "merged['trial_id_hits'] = merged['trial_id_hits'].apply(dedupe_list)\n",
    "merged.drop(['id_hits', 'abst_id_hits'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_hits_cond = [merged.reg_prefix_hits_x.notnull() & merged.reg_prefix_hits_y.isna(), \n",
    "                merged.reg_prefix_hits_x.isna() & merged.reg_prefix_hits_y.notnull(), \n",
    "                merged.reg_prefix_hits_x.notnull() & merged.reg_prefix_hits_y.notnull()]\n",
    "prefix_hits_output= [merged.reg_prefix_hits_x, merged.reg_prefix_hits_y, \n",
    "                     merged.reg_prefix_hits_x + merged.reg_prefix_hits_y]\n",
    "    \n",
    "    \n",
    "merged['prefix_hits'] = np.select(prefix_hits_cond, prefix_hits_output, None)\n",
    "merged['prefix_hits'] = merged['prefix_hits'].apply(dedupe_list)\n",
    "merged.drop(['reg_prefix_hits_x', 'reg_prefix_hits_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_name_hits_cond = [merged.reg_name_hits_x.notnull() & merged.reg_name_hits_y.isna(), \n",
    "                      merged.reg_name_hits_x.isna() & merged.reg_name_hits_y.notnull(), \n",
    "                      merged.reg_name_hits_x.notnull() & merged.reg_name_hits_y.notnull()]\n",
    "reg_name_hits_output= [merged.reg_name_hits_x, merged.reg_name_hits_y, \n",
    "                       merged.reg_name_hits_x + merged.reg_name_hits_y]\n",
    "    \n",
    "    \n",
    "merged['reg_name_hits'] = np.select(reg_name_hits_cond, reg_name_hits_output, None)\n",
    "merged['reg_name_hits'] = merged['reg_name_hits'].apply(dedupe_list)\n",
    "merged.drop(['reg_name_hits_x', 'reg_name_hits_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['id'] = np.where(merged.pm_id.isna(), merged.cord_uid, merged.pm_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merged.fillna(np.nan).groupby('id', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['id', 'trial_id_hits', 'prefix_hits', 'reg_name_hits', 'pub_types', 'doi', 'pm_id', \n",
    "                     'cord_uid', 'url', 'title', 'review_in_title', 'review_type']]\n",
    "\n",
    "final_df.columns = ['id', 'id_hits', 'prefix_hits', 'reg_name_hits', 'pub_types', 'doi', 'pm_id', 'cord_id', 'url', \n",
    "                    'title', 'review_in_title', 'review_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['pub_types'] = final_df.pub_types.astype(str).apply(trial_pub_type)\n",
    "final_df['doi_link'] = final_df.doi.apply(make_doi_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[((final_df.id_hits.notnull()) | (final_df.pub_types.notnull())) & \n",
    "         ((final_df.review_in_title != True) & (final_df.review_type != True)\n",
    "         )].to_csv(parent + '/data/final_auto_14Jul2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
